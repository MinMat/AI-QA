{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (4.30.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pytorch-pretrained-bert in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (4.30.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.14.5)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (0.4.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2.20.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.9.69)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (1.22)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2018.8.24)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.69 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (1.12.69)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.1.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.9.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.69->boto3->pytorch-pretrained-bert) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.69->boto3->pytorch-pretrained-bert) (2.7.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.69->boto3->pytorch-pretrained-bert) (1.11.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: keras in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (1.14.5)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras) (3.12)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (3.6.1)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.12.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.14.5)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow) (1.18.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (39.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install pytorch-pretrained-bert\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from tqdm import tqdm, trange\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnswering\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question Stem</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Complete Question</th>\n",
       "      <th>Answer Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7-980</td>\n",
       "      <td>The sun is responsible for</td>\n",
       "      <td>(A) puppies learning new tricks (B) children g...</td>\n",
       "      <td>The sun is responsible for (A) puppies learnin...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7-584</td>\n",
       "      <td>When standing miles away from Mount Rushmore</td>\n",
       "      <td>(A) the mountains seem very close (B) the moun...</td>\n",
       "      <td>When standing miles away from Mount Rushmore (...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-870</td>\n",
       "      <td>When food is reduced in the stomach</td>\n",
       "      <td>(A) the mind needs time to digest (B) take a s...</td>\n",
       "      <td>When food is reduced in the stomach (A) the mi...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                 Question Stem  \\\n",
       "0  7-980                    The sun is responsible for   \n",
       "1  7-584  When standing miles away from Mount Rushmore   \n",
       "2  7-870           When food is reduced in the stomach   \n",
       "\n",
       "                                             Choices  \\\n",
       "0  (A) puppies learning new tricks (B) children g...   \n",
       "1  (A) the mountains seem very close (B) the moun...   \n",
       "2  (A) the mind needs time to digest (B) take a s...   \n",
       "\n",
       "                                   Complete Question Answer Key  \n",
       "0  The sun is responsible for (A) puppies learnin...          D  \n",
       "1  When standing miles away from Mount Rushmore (...          D  \n",
       "2  When food is reduced in the stomach (A) the mi...          C  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"InferSent/encoder/data/train.tsv\",sep='\\t')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:21: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:15: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:17: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "#Create new features from the answer choices  \n",
    "for index, row in train.iterrows():\n",
    "    ans = re.split(\"(\\([A-Z]\\))\", row['Choices'])\n",
    "    ans.remove('')\n",
    "    train.set_value(index,'OptionA',ans[1])\n",
    "    train.set_value(index,'OptionB',ans[3])\n",
    "    train.set_value(index,'OptionC',ans[5])\n",
    "    train.set_value(index,'OptionD',ans[7])\n",
    "    \n",
    "#Find the answer key and replace it with the value   \n",
    "for index, row in train.iterrows():\n",
    "    ans = re.split(\"(\\([A-Z]\\))\", row['Choices'])\n",
    "    ans.remove('')\n",
    "    if row['Answer Key'] == 'A':\n",
    "        train.set_value(index,'Result',ans[1])\n",
    "    elif row['Answer Key'] == 'B':\n",
    "        train.set_value(index,'Result',ans[3])\n",
    "    elif row['Answer Key'] == 'C':\n",
    "        train.set_value(index,'Result',ans[5])\n",
    "    elif row['Answer Key'] == 'D':\n",
    "        train.set_value(index,'Result',ans[7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_categories = 4957\n",
    "shuffled = train.reindex(np.random.permutation(train.index))\n",
    "a = shuffled[shuffled['Answer Key'] == 'A'][:num_of_categories]\n",
    "b = shuffled[shuffled['Answer Key'] == 'B'][:num_of_categories]\n",
    "c = shuffled[shuffled['Answer Key'] == 'C'][:num_of_categories]\n",
    "d = shuffled[shuffled['Answer Key'] == 'D'][:num_of_categories]\n",
    "concated = pd.concat([a,b,c,d], ignore_index=True)\n",
    "#Shuffle the dataset\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "concated['LABEL'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2909    2\n",
      "2106    1\n",
      "4876    3\n",
      "3107    2\n",
      "4742    3\n",
      "3627    2\n",
      "1156    0\n",
      "4031    3\n",
      "250     0\n",
      "2473    1\n",
      "Name: LABEL, dtype: int64\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "#One-hot encode the labels\n",
    "concated.loc[concated['Answer Key'] == 'A', 'LABEL'] = 0\n",
    "concated.loc[concated['Answer Key'] == 'B', 'LABEL'] = 1\n",
    "concated.loc[concated['Answer Key'] == 'C','LABEL'] = 2\n",
    "concated.loc[concated['Answer Key'] == 'D','LABEL'] = 3\n",
    "print(concated['LABEL'][:10])\n",
    "labels = to_categorical(concated['LABEL'], num_classes=4)\n",
    "print(labels[:10])\n",
    "if 'CATEGORY' in concated.keys():\n",
    "    concated.drop(['CATEGORY'], axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question Stem</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Complete Question</th>\n",
       "      <th>Answer Key</th>\n",
       "      <th>OptionA</th>\n",
       "      <th>OptionB</th>\n",
       "      <th>OptionC</th>\n",
       "      <th>OptionD</th>\n",
       "      <th>Result</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>10-1207</td>\n",
       "      <td>New hydro-electric vehicles will result in gas...</td>\n",
       "      <td>(A) eventually earning a lot of money (B) bein...</td>\n",
       "      <td>New hydro-electric vehicles will result in gas...</td>\n",
       "      <td>C</td>\n",
       "      <td>eventually earning a lot of money</td>\n",
       "      <td>being blown up by the governor of California</td>\n",
       "      <td>eventually losing a lot of money</td>\n",
       "      <td>reporting record third quarter growth</td>\n",
       "      <td>eventually losing a lot of money</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>12-483</td>\n",
       "      <td>A way to illuminate a dark study is to</td>\n",
       "      <td>(A) spread a good idea (B) introduce a spark t...</td>\n",
       "      <td>A way to illuminate a dark study is to (A) spr...</td>\n",
       "      <td>B</td>\n",
       "      <td>spread a good idea</td>\n",
       "      <td>introduce a spark to a wick</td>\n",
       "      <td>open a small box</td>\n",
       "      <td>put a book down</td>\n",
       "      <td>introduce a spark to a wick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>11-530</td>\n",
       "      <td>A hang-glider that is soaring runs into gales ...</td>\n",
       "      <td>(A) sinks the glider (B) speeds the glider (C)...</td>\n",
       "      <td>A hang-glider that is soaring runs into gales ...</td>\n",
       "      <td>D</td>\n",
       "      <td>sinks the glider</td>\n",
       "      <td>speeds the glider</td>\n",
       "      <td>crashes the glider</td>\n",
       "      <td>slow the glider</td>\n",
       "      <td>slow the glider</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>399</td>\n",
       "      <td>The amount of transpiration is lower in</td>\n",
       "      <td>(A) summer (B) fall (C) winter (D) spring</td>\n",
       "      <td>The amount of transpiration is lower in (A) su...</td>\n",
       "      <td>C</td>\n",
       "      <td>summer</td>\n",
       "      <td>fall</td>\n",
       "      <td>winter</td>\n",
       "      <td>spring</td>\n",
       "      <td>winter</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>10-1159</td>\n",
       "      <td>the Earth rotating on its axis causes the sun ...</td>\n",
       "      <td>(A) dark hours (B) sunlight deficient (C) nigh...</td>\n",
       "      <td>the Earth rotating on its axis causes the sun ...</td>\n",
       "      <td>D</td>\n",
       "      <td>dark hours</td>\n",
       "      <td>sunlight deficient</td>\n",
       "      <td>night</td>\n",
       "      <td>waking hours</td>\n",
       "      <td>waking hours</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>12-331</td>\n",
       "      <td>Which of the following would best describe why...</td>\n",
       "      <td>(A) it can eat bugs and withstand very cold we...</td>\n",
       "      <td>Which of the following would best describe why...</td>\n",
       "      <td>C</td>\n",
       "      <td>it can eat bugs and withstand very cold weather</td>\n",
       "      <td>it can eat fish and withstand very cold weather</td>\n",
       "      <td>it can eat bugs and withstand very hot weather</td>\n",
       "      <td>it can eat fish and withstand very cold weather</td>\n",
       "      <td>it can eat bugs and withstand very hot weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>11-290</td>\n",
       "      <td>Which is a visible example of water vapor</td>\n",
       "      <td>(A) aerial clouds (B) snow (C) cigarette cloud...</td>\n",
       "      <td>Which is a visible example of water vapor (A) ...</td>\n",
       "      <td>A</td>\n",
       "      <td>aerial clouds</td>\n",
       "      <td>snow</td>\n",
       "      <td>cigarette clouds</td>\n",
       "      <td>ice</td>\n",
       "      <td>aerial clouds</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>325</td>\n",
       "      <td>During a sandstorm, a bird looks for a</td>\n",
       "      <td>(A) worm (B) mate (C) stream (D) bush</td>\n",
       "      <td>During a sandstorm, a bird looks for a (A) wor...</td>\n",
       "      <td>D</td>\n",
       "      <td>worm</td>\n",
       "      <td>mate</td>\n",
       "      <td>stream</td>\n",
       "      <td>bush</td>\n",
       "      <td>bush</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>9-972</td>\n",
       "      <td>If Paul is playing basketball and finds that h...</td>\n",
       "      <td>(A) His body is trying to lower its temperatur...</td>\n",
       "      <td>If Paul is playing basketball and finds that h...</td>\n",
       "      <td>A</td>\n",
       "      <td>His body is trying to lower its temperature</td>\n",
       "      <td>His heart is pumping too fast</td>\n",
       "      <td>His body is too cold</td>\n",
       "      <td>The girls watching him play think he looks hot</td>\n",
       "      <td>His body is trying to lower its temperature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>12-632</td>\n",
       "      <td>If a hill has a sharp decline on a side, water...</td>\n",
       "      <td>(A) a flat edge (B) sharpest side (C) everywhe...</td>\n",
       "      <td>If a hill has a sharp decline on a side, water...</td>\n",
       "      <td>B</td>\n",
       "      <td>a flat edge</td>\n",
       "      <td>sharpest side</td>\n",
       "      <td>everywhere</td>\n",
       "      <td>a softer side</td>\n",
       "      <td>sharpest side</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                      Question Stem  \\\n",
       "2909  10-1207  New hydro-electric vehicles will result in gas...   \n",
       "2106   12-483             A way to illuminate a dark study is to   \n",
       "4876   11-530  A hang-glider that is soaring runs into gales ...   \n",
       "3107      399            The amount of transpiration is lower in   \n",
       "4742  10-1159  the Earth rotating on its axis causes the sun ...   \n",
       "3627   12-331  Which of the following would best describe why...   \n",
       "1156   11-290          Which is a visible example of water vapor   \n",
       "4031      325             During a sandstorm, a bird looks for a   \n",
       "250     9-972  If Paul is playing basketball and finds that h...   \n",
       "2473   12-632  If a hill has a sharp decline on a side, water...   \n",
       "\n",
       "                                                Choices  \\\n",
       "2909  (A) eventually earning a lot of money (B) bein...   \n",
       "2106  (A) spread a good idea (B) introduce a spark t...   \n",
       "4876  (A) sinks the glider (B) speeds the glider (C)...   \n",
       "3107          (A) summer (B) fall (C) winter (D) spring   \n",
       "4742  (A) dark hours (B) sunlight deficient (C) nigh...   \n",
       "3627  (A) it can eat bugs and withstand very cold we...   \n",
       "1156  (A) aerial clouds (B) snow (C) cigarette cloud...   \n",
       "4031              (A) worm (B) mate (C) stream (D) bush   \n",
       "250   (A) His body is trying to lower its temperatur...   \n",
       "2473  (A) a flat edge (B) sharpest side (C) everywhe...   \n",
       "\n",
       "                                      Complete Question Answer Key  \\\n",
       "2909  New hydro-electric vehicles will result in gas...          C   \n",
       "2106  A way to illuminate a dark study is to (A) spr...          B   \n",
       "4876  A hang-glider that is soaring runs into gales ...          D   \n",
       "3107  The amount of transpiration is lower in (A) su...          C   \n",
       "4742  the Earth rotating on its axis causes the sun ...          D   \n",
       "3627  Which of the following would best describe why...          C   \n",
       "1156  Which is a visible example of water vapor (A) ...          A   \n",
       "4031  During a sandstorm, a bird looks for a (A) wor...          D   \n",
       "250   If Paul is playing basketball and finds that h...          A   \n",
       "2473  If a hill has a sharp decline on a side, water...          B   \n",
       "\n",
       "                                                OptionA  \\\n",
       "2909                 eventually earning a lot of money    \n",
       "2106                                spread a good idea    \n",
       "4876                                  sinks the glider    \n",
       "3107                                            summer    \n",
       "4742                                        dark hours    \n",
       "3627   it can eat bugs and withstand very cold weather    \n",
       "1156                                     aerial clouds    \n",
       "4031                                              worm    \n",
       "250        His body is trying to lower its temperature    \n",
       "2473                                       a flat edge    \n",
       "\n",
       "                                                OptionB  \\\n",
       "2909      being blown up by the governor of California    \n",
       "2106                       introduce a spark to a wick    \n",
       "4876                                 speeds the glider    \n",
       "3107                                              fall    \n",
       "4742                                sunlight deficient    \n",
       "3627   it can eat fish and withstand very cold weather    \n",
       "1156                                              snow    \n",
       "4031                                              mate    \n",
       "250                      His heart is pumping too fast    \n",
       "2473                                     sharpest side    \n",
       "\n",
       "                                               OptionC  \\\n",
       "2909                 eventually losing a lot of money    \n",
       "2106                                 open a small box    \n",
       "4876                               crashes the glider    \n",
       "3107                                           winter    \n",
       "4742                                            night    \n",
       "3627   it can eat bugs and withstand very hot weather    \n",
       "1156                                 cigarette clouds    \n",
       "4031                                           stream    \n",
       "250                              His body is too cold    \n",
       "2473                                       everywhere    \n",
       "\n",
       "                                               OptionD  \\\n",
       "2909             reporting record third quarter growth   \n",
       "2106                                   put a book down   \n",
       "4876                                   slow the glider   \n",
       "3107                                            spring   \n",
       "4742                                      waking hours   \n",
       "3627   it can eat fish and withstand very cold weather   \n",
       "1156                                               ice   \n",
       "4031                                              bush   \n",
       "250     The girls watching him play think he looks hot   \n",
       "2473                                     a softer side   \n",
       "\n",
       "                                                Result  LABEL  \n",
       "2909                 eventually losing a lot of money       2  \n",
       "2106                      introduce a spark to a wick       1  \n",
       "4876                                   slow the glider      3  \n",
       "3107                                           winter       2  \n",
       "4742                                      waking hours      3  \n",
       "3627   it can eat bugs and withstand very hot weather       2  \n",
       "1156                                    aerial clouds       0  \n",
       "4031                                              bush      3  \n",
       "250       His body is trying to lower its temperature       0  \n",
       "2473                                    sharpest side       1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1326\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "with open('InferSent/encoder/data/openbook.txt') as f:\n",
    "    for line in f:\n",
    "        sentences.append(line.strip())\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAExample(object):\n",
    "    \"\"\"A single training/test example for the SWAG dataset.\"\"\"\n",
    "    def __init__(self,\n",
    "                 QA_id,\n",
    "                 context_sentence,\n",
    "                 question_stem,\n",
    "                 ending_0,\n",
    "                 ending_1,\n",
    "                 ending_2,\n",
    "                 ending_3,\n",
    "                 label = None):\n",
    "        self.qa_id = QA_id\n",
    "        self.context_sentence = context_sentence\n",
    "        self.question_stem = question_stem\n",
    "        self.endings = [\n",
    "            ending_0,\n",
    "            ending_1,\n",
    "            ending_2,\n",
    "            ending_3,\n",
    "        ]\n",
    "        self.label = label\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,\n",
    "                 example_id,\n",
    "                 choices_features,\n",
    "                 label\n",
    "\n",
    "    ):\n",
    "        self.example_id = example_id\n",
    "        self.choices_features = [\n",
    "            {\n",
    "                'input_ids': input_ids,\n",
    "                'input_mask': input_mask,\n",
    "                'segment_ids': segment_ids\n",
    "            }\n",
    "            for _, input_ids, input_mask, segment_ids in choices_features\n",
    "        ]\n",
    "        self.label = label        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n",
    "\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)\n",
    "\n",
    "def select_field(features, field):\n",
    "    return [\n",
    "        [\n",
    "            choice[field]\n",
    "            for choice in feature.choices_features\n",
    "        ]\n",
    "        for feature in features\n",
    "    ]\n",
    "\n",
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " examples = [\n",
    "        QAExample(\n",
    "            QA_id = concated['ID'].values,\n",
    "            context_sentence = sentences,\n",
    "            question_stem = concated[\"Question Stem\"].values,\n",
    "            ending_0 = concated['OptionA'].values,\n",
    "            ending_1 = concated['OptionB'].values,\n",
    "            ending_2 = concated['OptionC'].values,\n",
    "            ending_3 = concated['OptionD'].values,\n",
    "            label = concated[\"LABEL\"].values\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/01/2019 08:55:15 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "features = []\n",
    "max_seq_length = 80\n",
    "for example_index, example in enumerate(examples):\n",
    "    \n",
    "    # tokenise the questions\n",
    "    context_sentence_tokens = tokenizer.tokenize(''.join(example.question_stem))\n",
    "  \n",
    "        \n",
    "    choices_features = [] \n",
    "    for ending_index, ending in enumerate(example.endings):\n",
    "        \n",
    "        #Select all the question tokens\n",
    "        context_tokens_sentence = context_sentence_tokens[:]\n",
    "        \n",
    "        #Select all the answer tokens\n",
    "        ending_tokens = tokenizer.tokenize(''.join(ending))\n",
    "        \n",
    "        _truncate_seq_pair(context_tokens_sentence, ending_tokens, max_seq_length - 3)\n",
    "        \n",
    "        \n",
    "        tokens = [\"[CLS]\"] + context_tokens_sentence + [\"[SEP]\"] + ending_tokens + [\"[SEP]\"]\n",
    "                                                          \n",
    "                                                                  \n",
    "        segment_ids = [0] * (len(context_tokens_sentence) + 2) + [1] * (len(ending_tokens) + 1)   \n",
    "     \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "      \n",
    "        input_mask = [1] * len(input_ids)\n",
    "      \n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        choices_features.append((tokens, input_ids, input_mask, segment_ids))\n",
    "        \n",
    "    for l in example.label:                                                              \n",
    "    # get the labels\n",
    "        labels = l \n",
    "                            \n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id = example.qa_id,\n",
    "                choices_features = choices_features,\n",
    "                label = labels\n",
    "            )\n",
    "        )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example_index, example in enumerate(features):\n",
    "#     print(example.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "local_rank = -1\n",
    "fp16 = \"\"\n",
    "no_cuda = \"\"\n",
    "gradient_accumulation_steps = 4\n",
    "seed = 42\n",
    "train_batch_size = 16\n",
    "do_train=True\n",
    "do_eval=True\n",
    "num_train_epochs = 3\n",
    "bert_model = 'bert-base-uncased'\n",
    "learning_rate = 2e-5\n",
    "warmup_proportion = 0.1\n",
    "loss_scale = 0\n",
    "train_features = features\n",
    "output_dir=os.getcwd() + \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/01/2019 08:55:45 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: \n"
     ]
    }
   ],
   "source": [
    "if  local_rank == -1 or no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(\"cuda\", local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "    device, n_gpu, bool(local_rank != -1), fp16))\n",
    "\n",
    "if gradient_accumulation_steps < 1:\n",
    "    raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                        gradient_accumulation_steps))\n",
    "\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/01/2019 09:06:42 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/ec2-user/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "02/01/2019 09:06:42 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/ec2-user/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpemkea9lu\n",
      "02/01/2019 09:06:46 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "02/01/2019 09:06:49 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultipleChoice not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "02/01/2019 09:06:49 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BertForMultipleChoice.from_pretrained('bert-base-uncased', num_choices=4)\n",
    "if fp16:\n",
    "    model.half()\n",
    "model.to(device)\n",
    "if local_rank != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4957"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_examples = None\n",
    "num_train_steps = None\n",
    "if do_train:\n",
    "    num_train_steps = int(len(train) / train_batch_size / gradient_accumulation_steps * num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/01/2019 09:07:10 - INFO - __main__ -   ***** Running training *****\n",
      "02/01/2019 09:07:10 - INFO - __main__ -     Num examples = 4957\n",
      "02/01/2019 09:07:10 - INFO - __main__ -     Batch size = 32\n",
      "02/01/2019 09:07:10 - INFO - __main__ -     Num steps = 464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4957, 4, 16]),\n",
       " torch.Size([4957, 4, 16]),\n",
       " torch.Size([4957, 4, 16]),\n",
       " torch.Size([4957]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# hack to remove pooler, which is not used\n",
    "# thus it produce None grad that break apex\n",
    "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "\n",
    "if local_rank != -1:\n",
    "    t_total = t_total // torch.distributed.get_world_size()\n",
    "if fp16:\n",
    "    try:\n",
    "        from apex.optimizers import FP16_Optimizer\n",
    "        from apex.optimizers import FusedAdam\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                          lr=learning_rate,\n",
    "                          bias_correction=False,\n",
    "                          max_grad_norm=1.0)\n",
    "    if loss_scale == 0:\n",
    "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "    else:\n",
    "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=loss_scale)\n",
    "else:\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=learning_rate,\n",
    "                     warmup=warmup_proportion,\n",
    "                     t_total=t_total)  \n",
    "\n",
    "input_ids = select_field(train_features, 'input_ids')\n",
    "flat_list_input_ids = []\n",
    "for item in input_ids:\n",
    "    flat_list_input_ids.append(item)\n",
    "\n",
    "input_mask = select_field(train_features, 'input_mask')\n",
    "flat_list_input_mask = []\n",
    "for item in input_mask:\n",
    "    flat_list_input_mask.append(item)\n",
    "\n",
    "\n",
    "segment_ids = select_field(train_features, 'segment_ids')\n",
    "flat_list_segment_ids = []\n",
    "for item in segment_ids:\n",
    "    flat_list_segment_ids.append(item)\n",
    "\n",
    "# labels_y=[]\n",
    "# for item in train_features:\n",
    "#     for label in item.label:\n",
    "#         labels_y.append(label)\n",
    "\n",
    "global_step = 0\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "#tags = pad_sequences([f.label for f in train_features],\n",
    "#                     maxlen=10, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "tags = [f.label for f in train_features]\n",
    "\n",
    "\n",
    "all_input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "all_segment_ids = torch.tensor(segment_ids, dtype=torch.long)\n",
    "all_input_mask = torch.tensor(input_mask, dtype=torch.long)\n",
    "all_label = torch.tensor(tags ,dtype=torch.long)\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,all_label)\n",
    "\n",
    "all_input_ids.size(),all_input_mask.size(),all_segment_ids.size(),all_label.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/155 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|          | 1/155 [00:01<03:24,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|         | 2/155 [00:02<02:59,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|         | 3/155 [00:02<02:42,  1.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|         | 4/155 [00:03<02:29,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|         | 5/155 [00:04<02:20,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|         | 6/155 [00:05<02:14,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|         | 7/155 [00:06<02:09,  1.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|         | 8/155 [00:07<02:05,  1.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|         | 9/155 [00:07<02:03,  1.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|         | 10/155 [00:08<02:01,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|         | 11/155 [00:09<01:59,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|         | 12/155 [00:10<01:57,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|         | 13/155 [00:11<01:56,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|         | 14/155 [00:11<01:55,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|         | 15/155 [00:12<01:54,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|         | 16/155 [00:13<01:53,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|         | 17/155 [00:14<01:52,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|        | 18/155 [00:15<01:51,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|        | 19/155 [00:15<01:50,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|        | 20/155 [00:16<01:49,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|        | 21/155 [00:17<01:49,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|        | 22/155 [00:18<01:48,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|        | 23/155 [00:19<01:47,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|        | 24/155 [00:20<01:46,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|        | 25/155 [00:20<01:45,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|        | 26/155 [00:21<01:45,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|        | 27/155 [00:22<01:44,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|        | 28/155 [00:23<01:43,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|        | 29/155 [00:24<01:42,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|        | 30/155 [00:24<01:41,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|        | 31/155 [00:25<01:40,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|        | 32/155 [00:26<01:40,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|       | 33/155 [00:27<01:39,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|       | 34/155 [00:28<01:38,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|       | 35/155 [00:29<01:37,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|       | 36/155 [00:29<01:36,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|       | 37/155 [00:30<01:36,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|       | 38/155 [00:31<01:35,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|       | 39/155 [00:32<01:34,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|       | 40/155 [00:33<01:33,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|       | 41/155 [00:33<01:33,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|       | 42/155 [00:34<01:32,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|       | 43/155 [00:35<01:31,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|       | 44/155 [00:36<01:30,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|       | 45/155 [00:37<01:29,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|       | 46/155 [00:38<01:29,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|       | 47/155 [00:38<01:28,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|       | 48/155 [00:39<01:27,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|      | 49/155 [00:40<01:26,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|      | 50/155 [00:41<01:25,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|      | 51/155 [00:42<01:25,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|      | 52/155 [00:42<01:24,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|      | 53/155 [00:43<01:23,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|      | 54/155 [00:44<01:22,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|      | 55/155 [00:45<01:21,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  36%|      | 56/155 [00:46<01:21,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|      | 57/155 [00:46<01:20,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|      | 58/155 [00:47<01:19,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|      | 59/155 [00:48<01:18,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|      | 60/155 [00:49<01:17,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|      | 61/155 [00:50<01:16,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  40%|      | 62/155 [00:51<01:16,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|      | 63/155 [00:51<01:15,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|     | 64/155 [00:52<01:14,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  42%|     | 65/155 [00:53<01:13,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|     | 66/155 [00:54<01:13,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|     | 67/155 [00:55<01:12,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|     | 68/155 [00:56<01:11,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|     | 69/155 [00:56<01:10,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|     | 70/155 [00:57<01:09,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|     | 71/155 [00:58<01:08,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|     | 72/155 [00:59<01:08,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|     | 73/155 [01:00<01:07,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|     | 74/155 [01:00<01:06,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|     | 75/155 [01:01<01:05,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  49%|     | 76/155 [01:02<01:05,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|     | 77/155 [01:03<01:04,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|     | 78/155 [01:04<01:03,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  51%|     | 79/155 [01:05<01:02,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|    | 80/155 [01:05<01:01,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|    | 81/155 [01:06<01:00,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|    | 82/155 [01:07<01:00,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|    | 83/155 [01:08<00:59,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|    | 84/155 [01:09<00:58,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|    | 85/155 [01:10<00:57,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|    | 86/155 [01:10<00:56,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|    | 87/155 [01:11<00:55,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|    | 88/155 [01:12<00:55,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|    | 89/155 [01:13<00:54,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  58%|    | 90/155 [01:14<00:53,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|    | 91/155 [01:14<00:52,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|    | 92/155 [01:15<00:51,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  60%|    | 93/155 [01:16<00:50,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|    | 94/155 [01:17<00:50,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|   | 95/155 [01:18<00:49,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|   | 96/155 [01:19<00:48,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|   | 97/155 [01:19<00:47,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|   | 98/155 [01:20<00:46,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  64%|   | 99/155 [01:21<00:46,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|   | 100/155 [01:22<00:45,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|   | 101/155 [01:23<00:44,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|   | 102/155 [01:24<00:43,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|   | 103/155 [01:24<00:42,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  67%|   | 104/155 [01:25<00:42,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|   | 105/155 [01:26<00:41,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|   | 106/155 [01:27<00:40,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|   | 107/155 [01:28<00:39,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|   | 108/155 [01:28<00:38,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|   | 109/155 [01:29<00:37,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  71%|   | 110/155 [01:30<00:37,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|  | 111/155 [01:31<00:36,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|  | 112/155 [01:32<00:35,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  73%|  | 113/155 [01:33<00:34,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|  | 114/155 [01:33<00:33,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|  | 115/155 [01:34<00:33,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|  | 116/155 [01:35<00:32,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|  | 117/155 [01:36<00:31,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  76%|  | 118/155 [01:37<00:30,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|  | 119/155 [01:38<00:29,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|  | 120/155 [01:38<00:28,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  78%|  | 121/155 [01:39<00:28,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|  | 122/155 [01:40<00:27,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|  | 123/155 [01:41<00:26,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  80%|  | 124/155 [01:42<00:25,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|  | 125/155 [01:42<00:24,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%| | 126/155 [01:43<00:23,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  82%| | 127/155 [01:44<00:23,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%| | 128/155 [01:45<00:22,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%| | 129/155 [01:46<00:21,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  84%| | 130/155 [01:47<00:20,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%| | 131/155 [01:47<00:19,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%| | 132/155 [01:48<00:19,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%| | 133/155 [01:49<00:18,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%| | 134/155 [01:50<00:17,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  87%| | 135/155 [01:51<00:16,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%| | 136/155 [01:52<00:15,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%| | 137/155 [01:52<00:14,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  89%| | 138/155 [01:53<00:14,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%| | 139/155 [01:54<00:13,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%| | 140/155 [01:55<00:12,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  91%| | 141/155 [01:56<00:11,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|| 142/155 [01:56<00:10,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|| 143/155 [01:57<00:09,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  93%|| 144/155 [01:58<00:09,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|| 145/155 [01:59<00:08,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|| 146/155 [02:00<00:07,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|| 147/155 [02:01<00:06,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|| 148/155 [02:01<00:05,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  96%|| 149/155 [02:02<00:04,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|| 150/155 [02:03<00:04,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|| 151/155 [02:04<00:03,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|| 152/155 [02:05<00:02,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|| 153/155 [02:06<00:01,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|| 154/155 [02:06<00:00,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 4, 16]) torch.Size([29, 4, 16]) torch.Size([29, 4, 16]) torch.Size([29])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  33%|      | 1/3 [02:07<04:15, 127.70s/it]\n",
      "Iteration:   0%|          | 0/155 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|          | 1/155 [00:00<02:07,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|         | 2/155 [00:01<02:06,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|         | 3/155 [00:02<02:05,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|         | 4/155 [00:03<02:05,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|         | 5/155 [00:04<02:04,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|         | 6/155 [00:04<02:03,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|         | 7/155 [00:05<02:02,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|         | 8/155 [00:06<02:01,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|         | 9/155 [00:07<02:00,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|         | 10/155 [00:08<01:59,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|         | 11/155 [00:09<01:58,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|         | 12/155 [00:09<01:58,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|         | 13/155 [00:10<01:57,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|         | 14/155 [00:11<01:56,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|         | 15/155 [00:12<01:55,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|         | 16/155 [00:13<01:55,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|         | 17/155 [00:14<01:54,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|        | 18/155 [00:14<01:53,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|        | 19/155 [00:15<01:52,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|        | 20/155 [00:16<01:51,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|        | 21/155 [00:17<01:51,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|        | 22/155 [00:18<01:50,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|        | 23/155 [00:19<01:49,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|        | 24/155 [00:19<01:48,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|        | 25/155 [00:20<01:47,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|        | 26/155 [00:21<01:47,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|        | 27/155 [00:22<01:46,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|        | 28/155 [00:23<01:45,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|        | 29/155 [00:24<01:44,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|        | 30/155 [00:24<01:43,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|        | 31/155 [00:25<01:42,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|        | 32/155 [00:26<01:42,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|       | 33/155 [00:27<01:41,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|       | 34/155 [00:28<01:40,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|       | 35/155 [00:29<01:39,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|       | 36/155 [00:29<01:38,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|       | 37/155 [00:30<01:38,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|       | 38/155 [00:31<01:37,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|       | 39/155 [00:32<01:36,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|       | 40/155 [00:33<01:35,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|       | 41/155 [00:33<01:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|       | 42/155 [00:34<01:33,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|       | 43/155 [00:35<01:33,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|       | 44/155 [00:36<01:32,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|       | 45/155 [00:37<01:31,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|       | 46/155 [00:38<01:30,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|       | 47/155 [00:38<01:29,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|       | 48/155 [00:39<01:29,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|      | 49/155 [00:40<01:28,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|      | 50/155 [00:41<01:27,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|      | 51/155 [00:42<01:26,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|      | 52/155 [00:43<01:25,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|      | 53/155 [00:43<01:24,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|      | 54/155 [00:44<01:23,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|      | 55/155 [00:45<01:23,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  36%|      | 56/155 [00:46<01:22,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|      | 57/155 [00:47<01:21,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|      | 58/155 [00:48<01:20,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|      | 59/155 [00:48<01:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|      | 60/155 [00:49<01:18,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|      | 61/155 [00:50<01:18,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  40%|      | 62/155 [00:51<01:17,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|      | 63/155 [00:52<01:16,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|     | 64/155 [00:53<01:15,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  42%|     | 65/155 [00:53<01:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|     | 66/155 [00:54<01:13,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|     | 67/155 [00:55<01:13,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|     | 68/155 [00:56<01:12,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|     | 69/155 [00:57<01:11,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|     | 70/155 [00:58<01:10,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|     | 71/155 [00:58<01:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|     | 72/155 [00:59<01:08,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|     | 73/155 [01:00<01:08,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|     | 74/155 [01:01<01:07,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|     | 75/155 [01:02<01:06,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  49%|     | 76/155 [01:03<01:05,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|     | 77/155 [01:03<01:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|     | 78/155 [01:04<01:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  51%|     | 79/155 [01:05<01:03,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|    | 80/155 [01:06<01:02,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|    | 81/155 [01:07<01:01,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|    | 82/155 [01:08<01:00,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|    | 83/155 [01:08<00:59,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|    | 84/155 [01:09<00:59,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|    | 85/155 [01:10<00:58,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|    | 86/155 [01:11<00:57,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|    | 87/155 [01:12<00:56,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|    | 88/155 [01:13<00:55,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|    | 89/155 [01:13<00:54,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  58%|    | 90/155 [01:14<00:54,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|    | 91/155 [01:15<00:53,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|    | 92/155 [01:16<00:52,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  60%|    | 93/155 [01:17<00:51,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|    | 94/155 [01:18<00:50,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|   | 95/155 [01:18<00:49,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|   | 96/155 [01:19<00:49,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|   | 97/155 [01:20<00:48,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|   | 98/155 [01:21<00:47,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  64%|   | 99/155 [01:22<00:46,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|   | 100/155 [01:23<00:45,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|   | 101/155 [01:23<00:44,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|   | 102/155 [01:24<00:44,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|   | 103/155 [01:25<00:43,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  67%|   | 104/155 [01:26<00:42,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|   | 105/155 [01:27<00:41,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|   | 106/155 [01:28<00:40,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|   | 107/155 [01:28<00:39,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|   | 108/155 [01:29<00:39,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|   | 109/155 [01:30<00:38,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  71%|   | 110/155 [01:31<00:37,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|  | 111/155 [01:32<00:36,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|  | 112/155 [01:33<00:35,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  73%|  | 113/155 [01:33<00:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|  | 114/155 [01:34<00:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|  | 115/155 [01:35<00:33,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|  | 116/155 [01:36<00:32,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|  | 117/155 [01:37<00:31,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  76%|  | 118/155 [01:37<00:30,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|  | 119/155 [01:38<00:30,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|  | 120/155 [01:39<00:29,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  78%|  | 121/155 [01:40<00:28,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|  | 122/155 [01:41<00:27,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|  | 123/155 [01:42<00:26,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  80%|  | 124/155 [01:43<00:25,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|  | 125/155 [01:43<00:25,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%| | 126/155 [01:44<00:24,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  82%| | 127/155 [01:45<00:23,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%| | 128/155 [01:46<00:22,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%| | 129/155 [01:47<00:21,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  84%| | 130/155 [01:48<00:20,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%| | 131/155 [01:48<00:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%| | 132/155 [01:49<00:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%| | 133/155 [01:50<00:18,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%| | 134/155 [01:51<00:17,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  87%| | 135/155 [01:52<00:16,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%| | 136/155 [01:52<00:15,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%| | 137/155 [01:53<00:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  89%| | 138/155 [01:54<00:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%| | 139/155 [01:55<00:13,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%| | 140/155 [01:56<00:12,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  91%| | 141/155 [01:57<00:11,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|| 142/155 [01:57<00:10,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|| 143/155 [01:58<00:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  93%|| 144/155 [01:59<00:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|| 145/155 [02:00<00:08,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|| 146/155 [02:01<00:07,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|| 147/155 [02:02<00:06,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|| 148/155 [02:02<00:05,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  96%|| 149/155 [02:03<00:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|| 150/155 [02:04<00:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|| 151/155 [02:05<00:03,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|| 152/155 [02:06<00:02,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|| 153/155 [02:07<00:01,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|| 154/155 [02:07<00:00,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 4, 16]) torch.Size([29, 4, 16]) torch.Size([29, 4, 16]) torch.Size([29])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  67%|   | 2/3 [04:16<02:08, 128.02s/it]\n",
      "Iteration:   0%|          | 0/155 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|          | 1/155 [00:00<02:08,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|         | 2/155 [00:01<02:07,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|         | 3/155 [00:02<02:06,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|         | 4/155 [00:03<02:05,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|         | 5/155 [00:04<02:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|         | 6/155 [00:04<02:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|         | 7/155 [00:05<02:03,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|         | 8/155 [00:06<02:02,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|         | 9/155 [00:07<02:01,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|         | 10/155 [00:08<02:00,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|         | 11/155 [00:09<01:59,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|         | 12/155 [00:09<01:58,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|         | 13/155 [00:10<01:58,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|         | 14/155 [00:11<01:57,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|         | 15/155 [00:12<01:56,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|         | 16/155 [00:13<01:55,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|         | 17/155 [00:14<01:55,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|        | 18/155 [00:14<01:54,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|        | 19/155 [00:15<01:53,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|        | 20/155 [00:16<01:52,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|        | 21/155 [00:17<01:51,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|        | 22/155 [00:18<01:50,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|        | 23/155 [00:19<01:49,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|        | 24/155 [00:19<01:48,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|        | 25/155 [00:20<01:48,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|        | 26/155 [00:21<01:47,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|        | 27/155 [00:22<01:46,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|        | 28/155 [00:23<01:45,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|        | 29/155 [00:24<01:44,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|        | 30/155 [00:24<01:43,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|        | 31/155 [00:25<01:43,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|        | 32/155 [00:26<01:42,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|       | 33/155 [00:27<01:41,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|       | 34/155 [00:28<01:40,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|       | 35/155 [00:29<01:39,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|       | 36/155 [00:29<01:38,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|       | 37/155 [00:30<01:38,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|       | 38/155 [00:31<01:37,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|       | 39/155 [00:32<01:36,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|       | 40/155 [00:33<01:35,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|       | 41/155 [00:34<01:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|       | 42/155 [00:34<01:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|       | 43/155 [00:35<01:33,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|       | 44/155 [00:36<01:32,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|       | 45/155 [00:37<01:31,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|       | 46/155 [00:38<01:30,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|       | 47/155 [00:39<01:29,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|       | 48/155 [00:39<01:29,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|      | 49/155 [00:40<01:28,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|      | 50/155 [00:41<01:27,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|      | 51/155 [00:42<01:26,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|      | 52/155 [00:43<01:25,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|      | 53/155 [00:44<01:24,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|      | 54/155 [00:44<01:24,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|      | 55/155 [00:45<01:23,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  36%|      | 56/155 [00:46<01:22,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|      | 57/155 [00:47<01:21,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|      | 58/155 [00:48<01:20,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|      | 59/155 [00:49<01:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|      | 60/155 [00:49<01:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|      | 61/155 [00:50<01:18,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  40%|      | 62/155 [00:51<01:17,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|      | 63/155 [00:52<01:16,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|     | 64/155 [00:53<01:15,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  42%|     | 65/155 [00:54<01:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|     | 66/155 [00:54<01:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|     | 67/155 [00:55<01:13,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|     | 68/155 [00:56<01:12,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|     | 69/155 [00:57<01:11,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|     | 70/155 [00:58<01:10,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|     | 71/155 [00:59<01:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|     | 72/155 [00:59<01:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|     | 73/155 [01:00<01:08,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|     | 74/155 [01:01<01:07,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|     | 75/155 [01:02<01:06,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  49%|     | 76/155 [01:03<01:05,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|     | 77/155 [01:04<01:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|     | 78/155 [01:04<01:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  51%|     | 79/155 [01:05<01:03,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|    | 80/155 [01:06<01:02,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|    | 81/155 [01:07<01:01,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|    | 82/155 [01:08<01:00,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|    | 83/155 [01:09<01:00,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|    | 84/155 [01:09<00:59,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|    | 85/155 [01:10<00:58,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|    | 86/155 [01:11<00:57,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|    | 87/155 [01:12<00:56,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|    | 88/155 [01:13<00:55,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|    | 89/155 [01:14<00:54,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  58%|    | 90/155 [01:14<00:54,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|    | 91/155 [01:15<00:53,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|    | 92/155 [01:16<00:52,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  60%|    | 93/155 [01:17<00:51,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|    | 94/155 [01:18<00:50,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|   | 95/155 [01:19<00:49,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|   | 96/155 [01:19<00:49,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|   | 97/155 [01:20<00:48,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|   | 98/155 [01:21<00:47,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  64%|   | 99/155 [01:22<00:46,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|   | 100/155 [01:23<00:45,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|   | 101/155 [01:24<00:44,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|   | 102/155 [01:24<00:44,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|   | 103/155 [01:25<00:43,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  67%|   | 104/155 [01:26<00:42,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|   | 105/155 [01:27<00:41,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|   | 106/155 [01:28<00:40,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|   | 107/155 [01:29<00:39,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|   | 108/155 [01:29<00:39,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|   | 109/155 [01:30<00:38,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  71%|   | 110/155 [01:31<00:37,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|  | 111/155 [01:32<00:36,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|  | 112/155 [01:33<00:35,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  73%|  | 113/155 [01:34<00:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|  | 114/155 [01:34<00:34,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|  | 115/155 [01:35<00:33,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|  | 116/155 [01:36<00:32,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|  | 117/155 [01:37<00:31,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  76%|  | 118/155 [01:38<00:30,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|  | 119/155 [01:39<00:30,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|  | 120/155 [01:39<00:29,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  78%|  | 121/155 [01:40<00:28,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|  | 122/155 [01:41<00:27,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|  | 123/155 [01:42<00:26,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  80%|  | 124/155 [01:43<00:25,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|  | 125/155 [01:44<00:24,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%| | 126/155 [01:44<00:24,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  82%| | 127/155 [01:45<00:23,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%| | 128/155 [01:46<00:22,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%| | 129/155 [01:47<00:21,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  84%| | 130/155 [01:48<00:20,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%| | 131/155 [01:49<00:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%| | 132/155 [01:49<00:19,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%| | 133/155 [01:50<00:18,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%| | 134/155 [01:51<00:17,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  87%| | 135/155 [01:52<00:16,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%| | 136/155 [01:53<00:15,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%| | 137/155 [01:54<00:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  89%| | 138/155 [01:54<00:14,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%| | 139/155 [01:55<00:13,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%| | 140/155 [01:56<00:12,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  91%| | 141/155 [01:57<00:11,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|| 142/155 [01:58<00:10,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|| 143/155 [01:59<00:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  93%|| 144/155 [01:59<00:09,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|| 145/155 [02:00<00:08,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|| 146/155 [02:01<00:07,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|| 147/155 [02:02<00:06,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|| 148/155 [02:03<00:05,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  96%|| 149/155 [02:03<00:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|| 150/155 [02:04<00:04,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|| 151/155 [02:05<00:03,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|| 152/155 [02:06<00:02,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|| 153/155 [02:07<00:01,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32, 4, 16]) torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|| 154/155 [02:08<00:00,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29, 4, 16]) torch.Size([29, 4, 16]) torch.Size([29, 4, 16]) torch.Size([29])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|| 3/3 [06:25<00:00, 128.30s/it]\n"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,all_label)\n",
    "\n",
    "\n",
    "for _ in trange(3, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        print(input_ids.shape,input_mask.shape,segment_ids.shape,label_ids.shape)\n",
    "        loss = model(input_ids, input_mask,segment_ids,label_ids)\n",
    "\n",
    "\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "\n",
    "        if fp16 and loss_scale != 1.0:\n",
    "            # rescale loss for fp16 training\n",
    "            # see https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html\n",
    "            loss = loss * loss_scale\n",
    "\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "        if fp16:\n",
    "            optimizer.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = learning_rate * warmup_linear(global_step/t_total, warmup_proportion)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/Thesismodels'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = os.path.join(output_dir, \"pytorch_model.bin\")\n",
    "if do_train:\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/01/2019 09:14:28 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/ec2-user/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "02/01/2019 09:14:28 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /home/ec2-user/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpkxkkpk3_\n",
      "02/01/2019 09:14:32 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(output_model_file)\n",
    "model_saved = BertForMultipleChoice.from_pretrained(bert_model, state_dict=model_state_dict, num_choices=4)\n",
    "model_saved.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"InferSent/encoder/data/test.tsv\",sep='\\t')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:6: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:17: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:15: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:21: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "#Create new features from the answer choices  \n",
    "for index, row in test.iterrows():\n",
    "    ans = re.split(\"(\\([A-Z]\\))\", row['Choices'])\n",
    "    ans.remove('')\n",
    "    test.set_value(index,'OptionA',ans[1])\n",
    "    test.set_value(index,'OptionB',ans[3])\n",
    "    test.set_value(index,'OptionC',ans[5])\n",
    "    test.set_value(index,'OptionD',ans[7])\n",
    "    \n",
    "#Find the answer key and replace it with the value   \n",
    "for index, row in test.iterrows():\n",
    "    ans = re.split(\"(\\([A-Z]\\))\", row['Choices'])\n",
    "    ans.remove('')\n",
    "    if row['Answer Key'] == 'A':\n",
    "        test.set_value(index,'Result',ans[1])\n",
    "    elif row['Answer Key'] == 'B':\n",
    "        test.set_value(index,'Result',ans[3])\n",
    "    elif row['Answer Key'] == 'C':\n",
    "        test.set_value(index,'Result',ans[5])\n",
    "    elif row['Answer Key'] == 'D':\n",
    "        test.set_value(index,'Result',ans[7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 11)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 126 132 104\n"
     ]
    }
   ],
   "source": [
    "num_of_categories_test = 500\n",
    "shuffled_test = test.reindex(np.random.permutation(test.index))\n",
    "\n",
    "a_test = shuffled_test[shuffled_test['Answer Key'] == 'A'][:num_of_categories_test]\n",
    "b_test = shuffled_test[shuffled_test['Answer Key'] == 'B'][:num_of_categories_test]\n",
    "c_test = shuffled_test[shuffled_test['Answer Key'] == 'C'][:num_of_categories_test]\n",
    "d_test = shuffled_test[shuffled_test['Answer Key'] == 'D'][:num_of_categories_test]\n",
    "\n",
    "concated_test = pd.concat([a_test,b_test,c_test,d_test], ignore_index=True)\n",
    "print(len(a_test),len(b_test),len(c_test),len(d_test))\n",
    "\n",
    "#Shuffle the dataset\n",
    "concated_test = concated_test.reindex(np.random.permutation(concated_test.index))\n",
    "concated_test['LABEL'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "286    2\n",
      "190    1\n",
      "367    2\n",
      "306    2\n",
      "68     0\n",
      "130    0\n",
      "351    2\n",
      "175    1\n",
      "443    3\n",
      "Name: LABEL, dtype: int64\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "#One-hot encode the labels\n",
    "concated_test.loc[concated_test['Answer Key'] == 'A', 'LABEL'] = 0\n",
    "concated_test.loc[concated_test['Answer Key'] == 'B', 'LABEL'] = 1\n",
    "concated_test.loc[concated_test['Answer Key'] == 'C','LABEL'] = 2\n",
    "concated_test.loc[concated_test['Answer Key'] == 'D','LABEL'] = 3\n",
    "print(concated_test['LABEL'][:10])\n",
    "labels_test = to_categorical(concated_test['LABEL'], num_classes=4)\n",
    "print(labels_test[:10])\n",
    "if 'CATEGORY' in concated_test.keys():\n",
    "    concated_test.drop(['CATEGORY'], axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    " test_examples = [\n",
    "        QAExample(\n",
    "            QA_id = concated_test['ID'].values,\n",
    "            context_sentence = sentences,\n",
    "            question_stem = concated_test[\"Question Stem\"].values,\n",
    "            ending_0 = concated_test['OptionA'].values,\n",
    "            ending_1 = concated_test['OptionB'].values,\n",
    "            ending_2 = concated_test['OptionC'].values,\n",
    "            ending_3 = concated_test['OptionD'].values,\n",
    "            label = concated_test[\"LABEL\"].values\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_test[\"LABEL\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "features = []\n",
    "max_seq_length = 16\n",
    "for example_index, example in enumerate(test_examples):\n",
    "    \n",
    "    # tokenise the questions\n",
    "    context_sentence_tokens = tokenizer.tokenize(''.join(example.question_stem))\n",
    "      \n",
    "        \n",
    "    test_choices_features = [] \n",
    "    for ending_index, ending in enumerate(example.endings):\n",
    "        \n",
    "        #Select all the question tokens\n",
    "        context_tokens_sentence = context_sentence_tokens[:]\n",
    "        \n",
    "        #Select all the answer tokens\n",
    "        ending_tokens = tokenizer.tokenize(''.join(ending))\n",
    "        \n",
    "        _truncate_seq_pair(context_tokens_sentence, ending_tokens, max_seq_length - 3)   \n",
    "        tokens = [\"[CLS]\"] + context_tokens_sentence + [\"[SEP]\"] + ending_tokens + [\"[SEP]\"]                                          \n",
    "        segment_ids = [0] * (len(context_tokens_sentence) + 2) + [1] * (len(ending_tokens) + 1)   \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "      \n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        test_choices_features.append((tokens, input_ids, input_mask, segment_ids))\n",
    "        \n",
    "    for l in example.label:                                                              \n",
    "    # get the labels\n",
    "        labels = l \n",
    "                            \n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                example_id = example.qa_id,\n",
    "                choices_features = test_choices_features,\n",
    "                label = labels\n",
    "            )\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/01/2019 09:21:25 - INFO - __main__ -   ***** Running training *****\n",
      "02/01/2019 09:21:25 - INFO - __main__ -     Num examples = 4957\n",
      "02/01/2019 09:21:25 - INFO - __main__ -     Batch size = 32\n",
      "02/01/2019 09:21:25 - INFO - __main__ -     Num steps = 464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 4, 16]),\n",
       " torch.Size([500, 4, 16]),\n",
       " torch.Size([500, 4, 16]),\n",
       " torch.Size([500]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = features\n",
    "input_ids = select_field(test_features, 'input_ids')\n",
    "input_mask = select_field(test_features, 'input_mask')\n",
    "segment_ids = select_field(test_features, 'segment_ids')\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train))\n",
    "logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "#tags = pad_sequences([f.label for f in train_features],\n",
    "#                     maxlen=10, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "tags = [f.label for f in test_features]\n",
    "\n",
    "\n",
    "all_input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "all_segment_ids = torch.tensor(segment_ids, dtype=torch.long)\n",
    "all_input_mask = torch.tensor(input_mask, dtype=torch.long)\n",
    "all_label = torch.tensor(tags ,dtype=torch.long)\n",
    "test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,all_label)\n",
    "\n",
    "all_input_ids.size(),all_input_mask.size(),all_segment_ids.size(),all_label.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction for full data\n",
    "predict_batch_size = 32\n",
    "eval_sampler = SequentialSampler(test_data)\n",
    "eval_dataloader = DataLoader(test_data, sampler=eval_sampler, batch_size=predict_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    nb_eval_examples += input_ids.size(0)\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "eval_loss = eval_loss / nb_eval_steps\n",
    "eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "\n",
    "result = {'eval_loss': eval_loss,\n",
    "          'eval_accuracy': eval_accuracy,\n",
    "          'global_step': global_step,\n",
    "          'loss': tr_loss/nb_tr_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.386153481900692,\n",
       " 'eval_accuracy': 0.264,\n",
       " 'global_step': 0,\n",
       " 'loss': 1.3862610478555002}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_eval_file = os.path.join(args.output_dir, \"eval_results.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 4])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions(eval_examples, eval_features, all_results,\n",
    "                  an_best_size, max_answer_length,\n",
    "                  do_lower_case, output_prediction_file,\n",
    "                  output_nbest_file, output_null_log_odds_file, verbose_logging, True, null_score_diff_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
